* Given matrix A and vector x;
* If Ax=0, then x is in null space of A. aka N(A)
* If Ax=cx, where c is  a scalar, then x is a eigenvector and c is the eigenvalue
* The number of eigenvectors and eigenvalues depend on ?(dimensionality of a?).
* Consider a square matrix A of size mxm. It has m eigenvalues.
* Sum of eigenvalues = trace(A)= sum of diagonal elements
* Product of eigenvalues = det(A)

![](pics/one.png)
* If A is square and A=A(t) (transpose), then its called symmetric matrix
  - aij=aji for all i and j

![](pics/two.png)


* If A is symmetric. And if all eigenvalues have same sign (all positive or all negative), then those are special symmetric matrices.
  * if all eigenvalues>=0; A is positive semidefinite
  * if all eigenvalues>0; A is positive definite
  * if all eigenvalues<=0; A is negative semidefinite
  * if all eigenvalues<0; A is negative definite


* Assume A is sqaure matrix, (may not be symmetric)
  * Trace - tr(A)- sum of diagonal elements = sum of eignvalues
  * Determinant of matrix= product of eigenvalues
    * Determinant=product of pivots
      * pivots==eigenvalues?
  * log (Det(A))= sum of eigenvalues (comes up helpful in max likelihood estimate, involving gaussian PDF)

* Properties involving multiple matrices
  * Trace of sum of matrices is sum of traces
  * Det of (product of matrices)= Product of determinants
  * $(A*B)^{-1}=B^{-1} * A^{-1}$
  * $(A*B)^{T}=B^{T} * A^{T}$
  * $(A^{-1})^{T}=(A^{T})^{-1}$


![](pics/yourscanfromsnelllibrary1/image0000.jpg)
![](pics/yourscanfromsnelllibrary1/image0001.jpg)
![](pics/yourscanfromsnelllibrary1/image0002.jpg)


* Derivative of matrix.

Ax, where A is matrix, x is vector. derivative (Ax) wrt x-  Jacobian matrix

https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant

![](pics/yourscanfromsnelllibrary1/image0003.jpg)
![](pics/yourscanfromsnelllibrary1/image0004.jpg)
![](pics/yourscanfromsnelllibrary1/image0005.jpg)
![](pics/yourscanfromsnelllibrary1/image0006.jpg)
![](pics/yourscanfromsnelllibrary1/image0007.jpg)
![](pics/yourscanfromsnelllibrary1/image0008.jpg)
- normal form of least squares
![](pics/yourscanfromsnelllibrary1/image0009.jpg)
![](pics/yourscanfromsnelllibrary1/image0010.jpg)
![](pics/yourscanfromsnelllibrary1/image0011.jpg)

* Further reading- Linear Algebra by Gilbert Strang (coming soon !)
